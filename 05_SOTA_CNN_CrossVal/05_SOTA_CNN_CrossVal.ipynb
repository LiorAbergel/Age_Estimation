{"cells":[{"cell_type":"markdown","metadata":{"id":"U4ShVeluU4Z2"},"source":["# Imports\n"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":3771,"status":"ok","timestamp":1755098009903,"user":{"displayName":"Lior Abergel","userId":"14776561249445909149"},"user_tz":-180},"id":"n9mYBgch2fac"},"outputs":[],"source":["# System and OS utilities\n","import os, math, itertools, warnings, gc\n","from collections import defaultdict\n","from google.colab import drive\n","from os.path import join\n","\n","# Data manipulation and processing\n","import numpy as np\n","import pandas as pd\n","\n","# TensorFlow and Keras\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential, Model\n","from tensorflow.keras.layers import (\n","    Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Input, GlobalAveragePooling2D\n",")\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n","from tensorflow.keras.applications import (\n","    ResNet50, EfficientNetB0, InceptionV3, InceptionResNetV2, DenseNet121\n",")\n","from tensorflow.keras.applications.efficientnet_v2 import EfficientNetV2M\n","\n","# Scikit-learn for data preprocessing and splitting\n","from sklearn.model_selection import train_test_split, StratifiedGroupKFold\n","from sklearn.preprocessing import MinMaxScaler\n","\n","# Image processing\n","from PIL import Image\n","\n","# Utility libraries\n","from tqdm import tqdm\n","\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1755098010757,"user":{"displayName":"Lior Abergel","userId":"14776561249445909149"},"user_tz":-180},"id":"vEk0Sg2_59HX","outputId":"c90450f2-5ee1-485f-c3cb-42e49a3f5bee"},"outputs":[{"output_type":"stream","name":"stdout","text":["Num GPUs Available:  1\n"]}],"source":["print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24237,"status":"ok","timestamp":1755098034997,"user":{"displayName":"Lior Abergel","userId":"14776561249445909149"},"user_tz":-180},"id":"dzPIht7I1wwG","outputId":"d9c26db8-7072-47a0-faac-a778977fb532"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["drive.mount('/content/drive')\n","\n","# Load the images\n","DATA_ROOT = '/content/drive/MyDrive/Expanded_HHD_AgeSplit'\n","\n","# Load the CSV file\n","csv_dir = os.path.join(DATA_ROOT, 'NewAgeSplit.csv')\n","labels_data = pd.read_csv(csv_dir)"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1755098035010,"user":{"displayName":"Lior Abergel","userId":"14776561249445909149"},"user_tz":-180},"id":"6gkf8ItL5uDg"},"outputs":[],"source":["BATCH_SIZE = 64"]},{"cell_type":"markdown","metadata":{"id":"lGzNH3t4U97V"},"source":["# Training\n"]},{"cell_type":"markdown","metadata":{"id":"G1PwyLPKN_mf"},"source":["## Loading Images and Preprocessing\n"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1755098046657,"user":{"displayName":"Lior Abergel","userId":"14776561249445909149"},"user_tz":-180},"id":"Aw7UOwd4BhwY"},"outputs":[],"source":["def calculate_resized_dimensions(height, width, patch_size=400, stride=200, standard_size=800):\n","    \"\"\"\n","    Calculates resized dimensions to maintain aspect ratio, be compatible with patching, and close to a standard size.\n","\n","    Args:\n","        height (int): Original height of the image.\n","        width (int): Original width of the image.\n","        patch_size (int): Size of each patch (default 400).\n","        stride (int): Stride for patching (default 200).\n","        standard_size (int): Target standard size for the smaller dimension.\n","\n","    Returns:\n","        tuple: Resized height and width.\n","    \"\"\"\n","    aspect_ratio = width / height\n","\n","    # Scale dimensions such that the smaller side matches the standard size\n","    if height < width:\n","        new_height = standard_size\n","        new_width = int(new_height * aspect_ratio)\n","    else:\n","        new_width = standard_size\n","        new_height = int(new_width / aspect_ratio)\n","\n","    # Adjust dimensions to be compatible with patching\n","    def adjust_dimension(dim):\n","        remainder = (dim - patch_size) % stride\n","        return dim if remainder == 0 else dim - remainder\n","\n","    new_height = adjust_dimension(new_height)\n","    new_width = adjust_dimension(new_width)\n","\n","    return new_height, new_width"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":17,"status":"ok","timestamp":1755098046679,"user":{"displayName":"Lior Abergel","userId":"14776561249445909149"},"user_tz":-180},"id":"oTvo_ghY9Pei"},"outputs":[],"source":["def read_tiff_image_with_dynamic_resize(img_path):\n","    \"\"\"\n","    Reads a TIFF image, dynamically resizes it to be compatible with patches and standard size, and normalizes it.\n","\n","    Args:\n","        img_path (tf.Tensor): Path to the image file.\n","\n","    Returns:\n","        np.ndarray: Resized and normalized image as a NumPy array.\n","    \"\"\"\n","    img = Image.open(img_path.numpy().decode(\"utf-8\"))  # Load TIFF file\n","    img = img.convert('RGB')  # Convert to RGB if necessary\n","    original_size = img.size  # Original dimensions (width, height)\n","    new_height, new_width = calculate_resized_dimensions(original_size[1], original_size[0])\n","    img = img.resize((new_width, new_height), Image.Resampling.LANCZOS)  # Resize dynamically with LANCZOS\n","    img_array = np.array(img, dtype=np.float32) / 255.0  # Normalize pixel values\n","    return img_array"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":143,"status":"ok","timestamp":1755098046821,"user":{"displayName":"Lior Abergel","userId":"14776561249445909149"},"user_tz":-180},"id":"I7ZqNFhG2KKv"},"outputs":[],"source":["def process_image(row, root_dir, patch_size, step_size):\n","    \"\"\"\n","    Processes a row to load the corresponding image, extract patches, and assign labels.\n","\n","    Args:\n","        row (dict): Dictionary containing file path and label data.\n","        data_dir (str): Directory containing the images.\n","        patch_size (tuple): Size of each patch (height, width).\n","        step_size (int): Step size for extracting patches.\n","\n","    Returns:\n","        tuple: Patches and corresponding labels.\n","    \"\"\"\n","   # 1) turn the Python string into a tf.string scalar\n","    root = tf.constant(root_dir, dtype=tf.string)\n","\n","    # 2) these are SymbolicTensors of dtype tf.string\n","    subset = row['Set']   # e.g. b'train'\n","    fname  = row['File']  # e.g. b'img123.tif'\n","\n","    # 3) join them with TF ops, not os.path\n","    #    result is a tf.Tensor of dtype string like b'/â€¦/HHD_AgeSplit/train/img123.tif'\n","    img_path = tf.strings.join([root, subset, fname], separator=os.path.sep)\n","\n","    # 4) load & resize via py_function\n","    img = tf.py_function(\n","        func=read_tiff_image_with_dynamic_resize,\n","        inp=[img_path],\n","        Tout=tf.float32\n","    )\n","    img.set_shape([None, None, 3])   # preserve static rank\n","\n","    # 5) extract patches\n","    patches = tf.image.extract_patches(\n","        images=tf.expand_dims(img, 0),\n","        sizes=[1, patch_size[0], patch_size[1], 1],\n","        strides=[1, step_size, step_size, 1],\n","        rates=[1, 1, 1, 1],\n","        padding='VALID'\n","    )\n","    patches = tf.reshape(patches, [-1, patch_size[0], patch_size[1], 3])\n","\n","    # 6) labels\n","    labels = tf.fill([tf.shape(patches)[0]], row['Age'])\n","\n","    # Compute mean intensity per patch, then mask out â€œemptyâ€ ones\n","    #    (mean over H, W, C â†’ shape [num_patches])\n","    patch_means = tf.reduce_mean(patches, axis=[1, 2, 3])\n","    mask = patch_means > THR\n","\n","    patches = tf.boolean_mask(patches, mask)\n","    labels  = tf.boolean_mask(labels,  mask)\n","\n","    return patches, labels"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":149,"status":"ok","timestamp":1755098046987,"user":{"displayName":"Lior Abergel","userId":"14776561249445909149"},"user_tz":-180},"id":"9eFQygpsI_tZ"},"outputs":[],"source":["# Create the RandomRotation layer outside the augmentation function.\n","rotation_layer = tf.keras.layers.RandomRotation(factor=0.04167)\n","\n","def advanced_augmentation(image, label):\n","    # Apply random rotation using the pre-instantiated layer.\n","    image = rotation_layer(image, training=True)\n","\n","    # Random Zoom: Scale the image by a factor between 0.9 and 1.1.\n","    orig_shape = tf.shape(image)[:2]\n","    zoom_factor = tf.random.uniform([], 0.9, 1.1)\n","    new_size = tf.cast(tf.cast(orig_shape, tf.float32) * zoom_factor, tf.int32)\n","    image = tf.image.resize(image, new_size)\n","    # Crop or pad back to the original dimensions.\n","    image = tf.image.resize_with_crop_or_pad(image, orig_shape[0], orig_shape[1])\n","\n","    # Random Contrast (0.75â€“1.25)\n","    image = tf.image.random_contrast(image, lower=0.75, upper=1.25)\n","\n","    # Gaussian Noise: Add noise with a standard deviation of 0.05.\n","    noise = tf.random.normal(shape=tf.shape(image), mean=0.0, stddev=0.05)\n","    image = tf.clip_by_value(image + noise, 0., 1.)\n","\n","    return image, label"]},{"cell_type":"code","execution_count":9,"metadata":{"collapsed":true,"executionInfo":{"elapsed":35,"status":"ok","timestamp":1755098047020,"user":{"displayName":"Lior Abergel","userId":"14776561249445909149"},"user_tz":-180},"id":"flSxuFS_nNGd"},"outputs":[],"source":["def patch_data_tf_dataset_from_df(\n","    labels_df_subset,\n","    data_dir,\n","    patch_size=(400, 400),\n","    step_size=200,\n","    batch_size=BATCH_SIZE,\n","    augment=False\n","):\n","    \"\"\"\n","    Like patch_data_tf_dataset, but draws from an arbitrary DataFrame slice\n","    instead of filtering by 'Set'. Useful for k-fold splits.\n","\n","    Args:\n","        labels_df_subset (pd.DataFrame): Subset of labels_data for this fold.\n","        data_dir (str): Directory containing images (train/val/test all the same).\n","        patch_size (tuple): Patch height & width.\n","        step_size (int): Stride for patches.\n","        batch_size (int): tf.data batch size.\n","        augment (bool): Whether to apply advanced_augmentation.\n","\n","    Returns:\n","        tf.data.Dataset: Batched dataset of (patch, label) pairs.\n","    \"\"\"\n","    ds = tf.data.Dataset.from_tensor_slices(dict(labels_df_subset))\n","    ds = ds.map(\n","        lambda row: process_image(row, data_dir, patch_size, step_size),\n","        num_parallel_calls=tf.data.AUTOTUNE\n","    ).flat_map(\n","        lambda patches, labels: tf.data.Dataset.zip((\n","            tf.data.Dataset.from_tensor_slices(patches),\n","            tf.data.Dataset.from_tensor_slices(labels)\n","        ))\n","    )\n","    if augment:\n","        ds = ds.map(\n","            lambda img, lbl: advanced_augmentation(img, lbl),\n","            num_parallel_calls=tf.data.AUTOTUNE\n","        )\n","    return ds.batch(batch_size).prefetch(tf.data.AUTOTUNE)"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":99,"status":"ok","timestamp":1755098047122,"user":{"displayName":"Lior Abergel","userId":"14776561249445909149"},"user_tz":-180},"id":"xHmwfJuIFgsJ"},"outputs":[],"source":["# Define a function to create models using SOTA architectures\n","def build_sota_model(base_model_fn, input_shape=(400, 400, 3), dropout_rate=0.5):\n","    base_model = base_model_fn(weights='imagenet', include_top=False, input_shape=input_shape)\n","\n","    inputs = Input(shape=input_shape)\n","    x = base_model(inputs, training=False)\n","    x = GlobalAveragePooling2D()(x)\n","    x = Dropout(dropout_rate)(x)\n","    outputs = Dense(1, activation='linear')(x)  # Regression output\n","\n","    model = Model(inputs, outputs)\n","    return model"]},{"cell_type":"code","source":["# if 'mean_patch_intensity' not in CACHE:\n","#     train_data = labels_data[labels_data['Set'] == 'train']\n","#     sample_files = train_data.sample(n=200, random_state=42)['File']\n","#     vals = []\n","#     for f in sample_files:\n","#         # Convert the file path string to a TensorFlow constant before passing it\n","#         # to the tf.py_function wrapped function.\n","#         arr = read_tiff_image_with_dynamic_resize(tf.constant(os.path.join(train_dir, f)))\n","#         vals.append(arr.mean())\n","#     CACHE['mean_patch_intensity'] = np.mean(vals)\n","THR = 0.0054\n","print(f\"Empty-patch threshold set to {THR:.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Qj7BU_RNERNg","executionInfo":{"status":"ok","timestamp":1755098047180,"user_tz":-180,"elapsed":51,"user":{"displayName":"Lior Abergel","userId":"14776561249445909149"}},"outputId":"5f8a4487-cfaf-4dfe-f797-5695251da699"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Empty-patch threshold set to 0.0054\n"]}]},{"cell_type":"markdown","metadata":{"id":"xt19mFAVOSFd"},"source":["## Train"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":20,"status":"ok","timestamp":1755098050868,"user":{"displayName":"Lior Abergel","userId":"14776561249445909149"},"user_tz":-180},"id":"Nes4DYwwMmVI"},"outputs":[],"source":["from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n","\n","def compute_evaluation_metrics(true_images, predicted_images):\n","    \"\"\"\n","    Computes evaluation metrics for age prediction models.\n","\n","    Args:\n","        true_images (np.ndarray): Array of true ages grouped by image ID.\n","        predicted_images (np.ndarray): Array of predicted ages grouped by image ID.\n","\n","    Returns:\n","        dict: A dictionary containing various evaluation metrics.\n","    \"\"\"\n","    # Compute primary metrics\n","    mae = mean_absolute_error(true_images, predicted_images)\n","    rmse = np.sqrt(mean_squared_error(true_images, predicted_images))\n","    r2 = r2_score(true_images, predicted_images)\n","    mape = np.mean(np.abs((true_images - predicted_images) / true_images)) * 100\n","\n","    # Threshold calculations\n","    def percent_within_threshold(y_true, y_pred, threshold):\n","        errors = np.abs(y_true - y_pred)\n","        within = np.sum(errors <= threshold)\n","        return (within / len(y_true)) * 100\n","\n","    within_2 = percent_within_threshold(true_images, predicted_images, 2)\n","    within_5 = percent_within_threshold(true_images, predicted_images, 5)\n","    within_10 = percent_within_threshold(true_images, predicted_images, 10)\n","\n","    # Additional statistics\n","    errors = np.abs(true_images - predicted_images)\n","    max_error = np.max(errors)\n","    median_error = np.median(errors)\n","    cumulative_error_5 = np.mean(errors <= 5) * 100\n","\n","    # Compile metrics\n","    metrics = {\n","        \"MAE\": mae,\n","        \"RMSE\": rmse,\n","        \"R2\": r2,\n","        \"MAPE\": mape,\n","        \"Within Â±2 Years (%)\": within_2,\n","        \"Within Â±5 Years (%)\": within_5,\n","        \"Within Â±10 Years (%)\": within_10,\n","        \"Max Error\": max_error,\n","        \"Median Error\": median_error,\n","        \"Cumulative Error â‰¤ 5 Years (%)\": cumulative_error_5,\n","    }\n","\n","    for key, value in metrics.items():\n","        print(f\"{key}: {value:.2f}\")\n","\n","\n","    # Create plots\n","    errors_sorted = np.sort(errors)\n","    cumulative_percentage = np.arange(1, len(errors_sorted) + 1) / len(errors_sorted) * 100\n","\n","    fig, axs = plt.subplots(1, 2, figsize=(14, 5))\n","\n","    # Error Distribution Plot\n","    axs[0].hist(errors, bins=20, edgecolor='black')\n","    axs[0].set_title('Error Distribution')\n","    axs[0].set_xlabel('Prediction Error (Years)')\n","    axs[0].set_ylabel('Frequency')\n","\n","    # Cumulative Error Distribution Plot\n","    axs[1].plot(errors_sorted, cumulative_percentage)\n","    axs[1].set_title('Cumulative Error Distribution')\n","    axs[1].set_xlabel('Absolute Error (Years)')\n","    axs[1].set_ylabel('Cumulative Percentage (%)')\n","    axs[1].grid(True)\n","\n","    plt.tight_layout()\n","    plt.show()\n","\n","    return metrics"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":24,"status":"ok","timestamp":1755098050896,"user":{"displayName":"Lior Abergel","userId":"14776561249445909149"},"user_tz":-180},"id":"0AkZCpF5gYNx"},"outputs":[],"source":["# Group predictions by 'File' (ImageID)\n","def group_predictions_by_image_id(predictions_with_ids, labels_df):\n","    \"\"\"\n","    Groups predictions by their `image_id`.\n","    Args:\n","        predictions_with_ids (list): List of tuples (prediction, image_id).\n","        labels_df (pd.DataFrame): DataFrame containing true labels.\n","    Returns:\n","        tuple: Grouped predictions and true labels for each image.\n","    \"\"\"\n","    grouped_predictions = defaultdict(list)\n","    grouped_labels = defaultdict(list)\n","\n","    # Group predictions by `image_id`\n","    for pred, image_id in predictions_with_ids:\n","        # If image_id is bytes, decode; otherwise, use as-is.\n","        if isinstance(image_id, bytes):\n","            image_id_str = image_id.decode('utf-8')\n","        else:\n","            image_id_str = image_id\n","        grouped_predictions[image_id_str].append(pred)\n","\n","    # Match true labels from `labels_df`\n","    for _, row in labels_df.iterrows():\n","        file_id = row['File']\n","        if file_id in grouped_predictions:\n","            grouped_labels[file_id].append(row['Age'])\n","\n","    # Filter to only include image IDs present in both predictions and labels\n","    common_ids = set(grouped_predictions.keys()) & set(grouped_labels.keys())\n","\n","    predicted_images = [np.mean(grouped_predictions[img_id]) for img_id in common_ids]\n","    true_images = [np.mean(grouped_labels[img_id]) for img_id in common_ids]\n","\n","    return np.array(predicted_images), np.array(true_images)"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1755098050911,"user":{"displayName":"Lior Abergel","userId":"14776561249445909149"},"user_tz":-180},"id":"h5pxFIISg1cM"},"outputs":[],"source":["def process_row_with_id(row):\n","    \"\"\"\n","    Processes a row to generate patches, labels, and use 'File' as the ImageID.\n","    \"\"\"\n","    # Load patches and labels, pointing at the base HHD_AgeSplit folder\n","    patches, labels = process_image(row, DATA_ROOT, (400,400), 200)\n","\n","    # Use 'File' as the ImageID\n","    image_id = tf.fill([tf.shape(patches)[0]], row['File'])\n","    return patches, labels, image_id"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1755098050925,"user":{"displayName":"Lior Abergel","userId":"14776561249445909149"},"user_tz":-180},"id":"awXOfneyxUM_"},"outputs":[],"source":["def patch_data_tf_dataset_with_ids_from_df(\n","    df_subset,\n","    data_dir,\n","    patch_size=(400, 400),\n","    step_size=200,\n","    batch_size=128,\n","    augment=False,\n","):\n","    \"\"\"\n","    Like patch_data_tf_dataset_with_ids() but takes _any_ DataFrame slice â€“\n","    perfect for k-fold splits where val rows are no longer â€˜valâ€™ in Set.\n","    Yields (patch, label, image_id) batched.\n","    \"\"\"\n","    ds = (\n","        tf.data.Dataset.from_tensor_slices(dict(df_subset))\n","        .map(process_row_with_id, num_parallel_calls=tf.data.AUTOTUNE)   # âžœ (patches, labels, image_ids)\n","        .flat_map(\n","            lambda patches, labels, image_ids: tf.data.Dataset.zip(\n","                (\n","                    tf.data.Dataset.from_tensor_slices(patches),\n","                    tf.data.Dataset.from_tensor_slices(labels),\n","                    tf.data.Dataset.from_tensor_slices(image_ids),\n","                )\n","            )\n","        )\n","    )\n","\n","    if augment:\n","        ds = ds.map(\n","            lambda p, l, i: (tf.image.random_flip_left_right(p), l, i),\n","            num_parallel_calls=tf.data.AUTOTUNE,\n","        )\n","\n","    return ds.batch(batch_size).prefetch(tf.data.AUTOTUNE)"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1755098050930,"user":{"displayName":"Lior Abergel","userId":"14776561249445909149"},"user_tz":-180},"id":"0aw6HshalSvj"},"outputs":[],"source":["def make_sgkf_splits(df: pd.DataFrame, n_splits=5, random_state=42):\n","    \"\"\"\n","    Returns a list of (train_idx, val_idx) tuples produced by\n","    StratifiedGroupKFold on writer-level records.\n","\n","    â€¢  Stratification key  â†’  AgeGroup\n","    â€¢  Group key           â†’  WriterNumber\n","    \"\"\"\n","    sgkf = StratifiedGroupKFold(\n","        n_splits=n_splits,\n","        shuffle=True,\n","        random_state=random_state\n","    )\n","    # NOTE: splitter expects X, y, groups\n","    X      = df.index.values\n","    y      = df['AgeGroup'].values\n","    groups = df['WriterNumber'].values\n","\n","    return list(sgkf.split(X, y, groups))"]},{"cell_type":"code","execution_count":19,"metadata":{"executionInfo":{"elapsed":26,"status":"ok","timestamp":1755098141462,"user":{"displayName":"Lior Abergel","userId":"14776561249445909149"},"user_tz":-180},"id":"mvayOu1wQt46"},"outputs":[],"source":["def run_cv(\n","    df_full: pd.DataFrame,\n","    base_model_fn,\n","    model_name: str,\n","    n_splits: int = 5,\n","    epochs_init: int = 50,\n","    epochs_ft: int = 10,\n","    batch_size: int = 64,\n","    patch_size=(400,400),\n","    step_size=200,\n","    dropout=0.5,\n","):\n","    # 1) prepare folds\n","    sgkf = StratifiedGroupKFold(n_splits=n_splits, shuffle=True, random_state=42)\n","    splits = list(sgkf.split(df_full.index, df_full[\"AgeGroup\"], df_full[\"WriterNumber\"]))\n","    ckpt_dir = os.path.join(DATA_ROOT, \"CV_STRAT_GROUP\", model_name)\n","    os.makedirs(ckpt_dir, exist_ok=True)\n","\n","    fold_metrics = []\n","\n","    for fold, (train_idx, val_idx) in enumerate(splits, start=1):\n","        if model_name == \"InceptionResNetV2\":\n","            if fold in (1, 2, 5):\n","                continue\n","\n","        print(f\"\\nâ”€â”€ {model_name} Fold {fold}/{n_splits} â”€â”€\")\n","\n","        # === 2) slice dataframes ===\n","        train_df = df_full.iloc[train_idx].reset_index(drop=True)\n","        val_df   = df_full.iloc[val_idx].reset_index(drop=True)\n","\n","        # === 3) make datasets ===\n","        train_ds = patch_data_tf_dataset_from_df(\n","            train_df, DATA_ROOT,\n","            patch_size=patch_size, step_size=step_size,\n","            batch_size=batch_size, augment=True\n","        )\n","        val_ds   = patch_data_tf_dataset_from_df(\n","            val_df, DATA_ROOT,\n","            patch_size=patch_size, step_size=step_size,\n","            batch_size=batch_size, augment=False\n","        )\n","\n","        # === 4) build & warm-up train ===\n","        model = build_sota_model(base_model_fn,\n","                                 input_shape=(*patch_size,3),\n","                                 dropout_rate=dropout)\n","        backbone = model.layers[1]\n","        backbone.trainable = False\n","        model.compile(optimizer=\"adam\", loss=\"mse\", metrics=[\"mae\"])\n","\n","        ckpt_init = os.path.join(ckpt_dir, f\"{model_name}_fold{fold}_init.keras\")\n","        callbacks = [\n","            ModelCheckpoint(ckpt_init, monitor=\"val_mae\", save_best_only=True, verbose=1),\n","            ReduceLROnPlateau(monitor=\"val_mae\", factor=0.2, patience=4, verbose=1),\n","            EarlyStopping(    monitor=\"val_mae\", patience=8, restore_best_weights=True, verbose=1),\n","        ]\n","        history = model.fit(train_ds,\n","                            validation_data=val_ds,\n","                            epochs=epochs_init,\n","                            callbacks=callbacks,\n","                            verbose=2)\n","\n","        # === 5) CLEANUP before fine-tune ===\n","        print(\"ðŸ§¹ Clearing memory before fine-tuneâ€¦\")\n","        # delete large objects no longer needed\n","        del train_ds, val_ds, history, callbacks\n","        gc.collect()\n","        tf.keras.backend.clear_session()\n","        gc.collect()\n","\n","        # === 6) rebuild model & load warm-up weights ===\n","        model = build_sota_model(base_model_fn,\n","                                 input_shape=(*patch_size,3),\n","                                 dropout_rate=dropout)\n","        model.load_weights(ckpt_init)\n","        backbone = model.layers[1]\n","        backbone.trainable = True\n","        model.compile(optimizer=tf.keras.optimizers.Adam(1e-4),\n","                      loss=\"mse\", metrics=[\"mae\"])\n","\n","        # === 7) re-create datasets for fine-tune ===\n","        train_ds = patch_data_tf_dataset_from_df(\n","            train_df, DATA_ROOT,\n","            patch_size=patch_size, step_size=step_size,\n","            batch_size=batch_size, augment=True\n","        )\n","        val_ds   = patch_data_tf_dataset_from_df(\n","            val_df, DATA_ROOT,\n","            patch_size=patch_size, step_size=step_size,\n","            batch_size=batch_size, augment=False\n","        )\n","\n","        ckpt_ft = os.path.join(ckpt_dir, f\"{model_name}_fold{fold}_ft.keras\")\n","        callbacks = [\n","            ModelCheckpoint(ckpt_ft, monitor=\"val_mae\", save_best_only=True, verbose=1),\n","            ReduceLROnPlateau(monitor=\"val_mae\", factor=0.2, patience=4, verbose=1),\n","            EarlyStopping(    monitor=\"val_mae\", patience=8, restore_best_weights=True, verbose=1),\n","        ]\n","        history_ft = model.fit(train_ds,\n","                               validation_data=val_ds,\n","                               epochs=epochs_ft,\n","                               callbacks=callbacks,\n","                               verbose=2)\n","\n","        # === 8) EVALUATE (image-level) ===\n","        del train_ds, history_ft, callbacks    # free again before eval\n","        gc.collect()\n","\n","        val_ids_ds = patch_data_tf_dataset_with_ids_from_df(\n","            val_df, DATA_ROOT,\n","            patch_size=patch_size, step_size=step_size,\n","            batch_size=batch_size, augment=False\n","        )\n","        preds = []\n","        for patches, _, img_ids in val_ids_ds:\n","            p = model.predict(patches, verbose=0).ravel()\n","            preds.extend(zip(p, img_ids.numpy()))\n","\n","        y_pred_img, y_true_img = group_predictions_by_image_id(preds, val_df)\n","        metrics = compute_evaluation_metrics(y_true_img, y_pred_img)\n","        fold_metrics.append(metrics)\n","\n","        # pretty-print\n","        keys = [\"MAE\",\"RMSE\",\"R2\",\"MAPE\"]\n","        summary = \" â”‚ \".join(f\"{k} {metrics[k]:.2f}\" for k in keys if k in metrics)\n","        print(f\"Fold {fold}: {summary}\")\n","\n","        # === 9) FINAL CLEANUP of this fold ===\n","        del val_ids_ds, preds, y_pred_img, y_true_img\n","        del train_df, val_df, model\n","        gc.collect()\n","        tf.keras.backend.clear_session()\n","        gc.collect()\n","\n","    # === 10) AGGREGATE all folds ===\n","    print(\"\\nâ•â•â•â•â•â• CV SUMMARY â•â•â•â•â•â•\")\n","    for k in fold_metrics[0].keys():\n","        arr = np.array([fm[k] for fm in fold_metrics], dtype=float)\n","        print(f\"{k:<25}: {arr.mean():.2f} Â± {arr.std():.2f}\")\n","\n","    return fold_metrics"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nsStIkmLFLq0","colab":{"base_uri":"https://localhost:8080/"},"outputId":"963c04dc-d1c0-4a97-fc18-58af2bb59554"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","â”€â”€ InceptionResNetV2 Fold 3/5 â”€â”€\n","Epoch 1/50\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/trainers/epoch_iterator.py:160: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n","  self._interrupted_warning()\n"]},{"output_type":"stream","name":"stdout","text":["\n","Epoch 1: val_mae improved from inf to 13.92824, saving model to /content/drive/MyDrive/Expanded_HHD_AgeSplit/CV_STRAT_GROUP/InceptionResNetV2/InceptionResNetV2_fold3_init.keras\n","292/292 - 211s - 724ms/step - loss: 169.2527 - mae: 8.0736 - val_loss: 263.4067 - val_mae: 13.9282 - learning_rate: 1.0000e-03\n","Epoch 2/50\n","\n","Epoch 2: val_mae improved from 13.92824 to 13.40291, saving model to /content/drive/MyDrive/Expanded_HHD_AgeSplit/CV_STRAT_GROUP/InceptionResNetV2/InceptionResNetV2_fold3_init.keras\n","292/292 - 114s - 391ms/step - loss: 123.3526 - mae: 7.1972 - val_loss: 242.8941 - val_mae: 13.4029 - learning_rate: 1.0000e-03\n","Epoch 3/50\n","\n","Epoch 3: val_mae improved from 13.40291 to 12.99425, saving model to /content/drive/MyDrive/Expanded_HHD_AgeSplit/CV_STRAT_GROUP/InceptionResNetV2/InceptionResNetV2_fold3_init.keras\n","292/292 - 114s - 390ms/step - loss: 116.2239 - mae: 6.9646 - val_loss: 228.5027 - val_mae: 12.9943 - learning_rate: 1.0000e-03\n","Epoch 4/50\n","\n","Epoch 4: val_mae improved from 12.99425 to 12.62335, saving model to /content/drive/MyDrive/Expanded_HHD_AgeSplit/CV_STRAT_GROUP/InceptionResNetV2/InceptionResNetV2_fold3_init.keras\n","292/292 - 114s - 391ms/step - loss: 111.9247 - mae: 6.8868 - val_loss: 217.2238 - val_mae: 12.6234 - learning_rate: 1.0000e-03\n","Epoch 5/50\n","\n","Epoch 5: val_mae improved from 12.62335 to 12.36143, saving model to /content/drive/MyDrive/Expanded_HHD_AgeSplit/CV_STRAT_GROUP/InceptionResNetV2/InceptionResNetV2_fold3_init.keras\n","292/292 - 115s - 393ms/step - loss: 110.5038 - mae: 6.8985 - val_loss: 209.6470 - val_mae: 12.3614 - learning_rate: 1.0000e-03\n","Epoch 6/50\n","\n","Epoch 6: val_mae improved from 12.36143 to 12.19282, saving model to /content/drive/MyDrive/Expanded_HHD_AgeSplit/CV_STRAT_GROUP/InceptionResNetV2/InceptionResNetV2_fold3_init.keras\n","292/292 - 114s - 390ms/step - loss: 108.6056 - mae: 6.9035 - val_loss: 204.8871 - val_mae: 12.1928 - learning_rate: 1.0000e-03\n","Epoch 7/50\n","\n","Epoch 7: val_mae improved from 12.19282 to 11.98294, saving model to /content/drive/MyDrive/Expanded_HHD_AgeSplit/CV_STRAT_GROUP/InceptionResNetV2/InceptionResNetV2_fold3_init.keras\n","292/292 - 114s - 390ms/step - loss: 107.7233 - mae: 6.9258 - val_loss: 199.7551 - val_mae: 11.9829 - learning_rate: 1.0000e-03\n","Epoch 8/50\n","\n","Epoch 8: val_mae improved from 11.98294 to 11.88692, saving model to /content/drive/MyDrive/Expanded_HHD_AgeSplit/CV_STRAT_GROUP/InceptionResNetV2/InceptionResNetV2_fold3_init.keras\n","292/292 - 114s - 390ms/step - loss: 106.8381 - mae: 6.9328 - val_loss: 197.2823 - val_mae: 11.8869 - learning_rate: 1.0000e-03\n","Epoch 9/50\n","\n","Epoch 9: val_mae improved from 11.88692 to 11.72196, saving model to /content/drive/MyDrive/Expanded_HHD_AgeSplit/CV_STRAT_GROUP/InceptionResNetV2/InceptionResNetV2_fold3_init.keras\n","292/292 - 113s - 389ms/step - loss: 106.1781 - mae: 6.9614 - val_loss: 193.7045 - val_mae: 11.7220 - learning_rate: 1.0000e-03\n","Epoch 10/50\n","\n","Epoch 10: val_mae improved from 11.72196 to 11.63545, saving model to /content/drive/MyDrive/Expanded_HHD_AgeSplit/CV_STRAT_GROUP/InceptionResNetV2/InceptionResNetV2_fold3_init.keras\n","292/292 - 114s - 392ms/step - loss: 106.4017 - mae: 6.9865 - val_loss: 191.8715 - val_mae: 11.6355 - learning_rate: 1.0000e-03\n","Epoch 11/50\n","\n","Epoch 11: val_mae improved from 11.63545 to 11.62448, saving model to /content/drive/MyDrive/Expanded_HHD_AgeSplit/CV_STRAT_GROUP/InceptionResNetV2/InceptionResNetV2_fold3_init.keras\n","292/292 - 114s - 390ms/step - loss: 105.7919 - mae: 6.9737 - val_loss: 191.4956 - val_mae: 11.6245 - learning_rate: 1.0000e-03\n","Epoch 12/50\n","\n","Epoch 12: val_mae improved from 11.62448 to 11.54261, saving model to /content/drive/MyDrive/Expanded_HHD_AgeSplit/CV_STRAT_GROUP/InceptionResNetV2/InceptionResNetV2_fold3_init.keras\n","292/292 - 114s - 389ms/step - loss: 105.3935 - mae: 6.9983 - val_loss: 189.8628 - val_mae: 11.5426 - learning_rate: 1.0000e-03\n","Epoch 13/50\n"]}],"source":["# Define SOTA models\n","models = {\n","    # 'ResNet50': ResNet50,\n","    # 'DenseNet121': DenseNet121,\n","    # 'InceptionV3': InceptionV3,\n","    'InceptionResNetV2': InceptionResNetV2,\n","    'EfficientNetV2M': EfficientNetV2M\n","}\n","\n","df_full = pd.read_csv(csv_dir)\n","\n","cv_stats = {}\n","for name, fn in models.items():\n","    cv_stats[name] = run_cv(\n","        df_full = df_full,\n","        base_model_fn = fn,\n","        model_name    = name,\n","        n_splits      = 5,\n","        batch_size    = 64,\n","    )\n","\n","print(cv_stats)"]},{"cell_type":"code","source":["# ========= Minimum-Error Metric across Folds =========\n","import gc\n","from sklearn.model_selection import StratifiedGroupKFold\n","\n","min_error_stats = {}     # {model_name: (mean, std)}\n","\n","# 1) Re-create the CV splitter exactly as in run_cv\n","sgkf   = StratifiedGroupKFold(n_splits=5, shuffle=True, random_state=42)\n","splits = list(sgkf.split(df_full.index,\n","                         df_full[\"AgeGroup\"],\n","                         df_full[\"WriterNumber\"]))\n","\n","print(\"\\nâ•â•â•â•â•â• Minimum Absolute Error per Model â•â•â•â•â•â•\")\n","for model_name in models.keys():\n","    fold_min_errors = []\n","\n","    for fold, (_, test_idx) in enumerate(splits, start=1):\n","        # --- load the fine-tuned checkpoint for this fold ---\n","        ckpt_path = os.path.join(\n","            DATA_ROOT, \"CV_STRAT_GROUP\", model_name,\n","            f\"{model_name}_fold{fold}_ft.keras\"\n","        )\n","        # try to load finetuned model, if not existent, fallback to init trained model\n","        if not os.path.exists(ckpt_path):\n","            ckpt_path = os.path.join(\n","                DATA_ROOT, \"CV_STRAT_GROUP\", model_name,\n","                f\"{model_name}_fold{fold}_init.keras\"\n","            )\n","        model = tf.keras.models.load_model(ckpt_path, compile=False)\n","\n","        # --- prepare this foldâ€™s *test* data ---\n","        test_df = df_full.iloc[test_idx].reset_index(drop=True)\n","        test_ds = patch_data_tf_dataset_with_ids_from_df(\n","            test_df, DATA_ROOT,\n","            patch_size=(400, 400), step_size=200,\n","            batch_size=64, augment=False\n","        )\n","\n","        # --- run inference & aggregate to image-level ---\n","        preds = []\n","        for patches, _, img_ids in test_ds:\n","            p = model.predict(patches, verbose=0).ravel()\n","            preds.extend(zip(p, img_ids.numpy()))\n","\n","        y_pred_img, y_true_img = group_predictions_by_image_id(preds, test_df)\n","\n","        # --- compute this foldâ€™s *minimum* absolute error ---\n","        abs_errors = np.abs(np.array(y_pred_img) - np.array(y_true_img))\n","        fold_min_errors.append(abs_errors.min())\n","\n","        # --- tidy up memory before next fold ---\n","        del model, test_ds, preds, y_pred_img, y_true_img, abs_errors\n","        gc.collect()\n","        tf.keras.backend.clear_session()\n","        gc.collect()\n","\n","    # store & display results for this model\n","    mean_min = np.mean(fold_min_errors)\n","    std_min  = np.std(fold_min_errors)\n","    min_error_stats[model_name] = (mean_min, std_min)\n","    print(f\"{model_name:<15}: {mean_min:.2f} Â± {std_min:.2f}\")\n","\n","# min_error_stats now holds the summarised metric if you need it later\n"],"metadata":{"id":"NEVSn4t70N1J","executionInfo":{"status":"aborted","timestamp":1755098099304,"user_tz":-180,"elapsed":48628,"user":{"displayName":"Lior Abergel","userId":"14776561249445909149"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"abkqHkNVZiav"},"source":["# Evaluation\n"]},{"cell_type":"markdown","metadata":{"id":"ILgTHuUi0IUX"},"source":["## Methods"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ddDSafBkhzy7"},"outputs":[],"source":["def patch_data_tf_dataset_with_ids(\n","    data_dir, labels_df, dataset_type, patch_size=(400, 400), step_size=200, batch_size=BATCH_SIZE, augment=False\n","):\n","    \"\"\"\n","    Creates a TensorFlow dataset with patches and 'File' as ImageID.\n","    \"\"\"\n","    subset_df = labels_df[labels_df['Set'] == dataset_type].reset_index(drop=True)\n","    dataset = tf.data.Dataset.from_tensor_slices(dict(subset_df))\n","\n","    # Map the function to process rows\n","    dataset = dataset.map(\n","        process_row_with_id,\n","        num_parallel_calls=tf.data.AUTOTUNE\n","    )\n","\n","    # Flatten dataset to yield individual patches\n","    dataset = dataset.flat_map(\n","        lambda patches, labels, image_id: tf.data.Dataset.zip(\n","            (\n","                tf.data.Dataset.from_tensor_slices(patches),\n","                tf.data.Dataset.from_tensor_slices(labels),\n","                tf.data.Dataset.from_tensor_slices(image_id) # Keep image_id here\n","            )\n","        )\n","    )\n","\n","    # Apply augmentation if required\n","    if augment:\n","        dataset = dataset.map(\n","            lambda patch, label, image_id: (tf.image.random_flip_left_right(patch), label, image_id),\n","            num_parallel_calls=tf.data.AUTOTUNE\n","        )\n","\n","    # Batch and prefetch\n","    dataset = dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n","    return dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"rdinwsk1FluF"},"outputs":[],"source":["def ensemble_predict(models, test_data):\n","    \"\"\"\n","    Makes predictions using an ensemble of models by averaging their outputs.\n","    Args:\n","        models (dict): A dictionary of trained models.\n","        test_data (tf.data.Dataset): Test dataset.\n","    Returns:\n","        list: A list of tuples containing predictions and image IDs.\n","    \"\"\"\n","    predictions = []\n","    for batch in test_data:\n","        patches, _, image_ids = batch\n","\n","        batch_preds = [model.predict(patches, verbose=0) for model in models.values()]\n","        avg_preds = np.mean(batch_preds, axis=0)\n","        predictions.extend(zip(avg_preds.flatten(), image_ids.numpy()))\n","\n","    return predictions"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9l6i4qBUHYaA"},"outputs":[],"source":["def ensemble_predict_with_weights(models, test_data, weights=None):\n","    \"\"\"\n","    Makes predictions using an ensemble of models by computing a weighted average of their outputs.\n","\n","    Args:\n","        models (dict): A dictionary of trained models.\n","        test_data (tf.data.Dataset): Test dataset.\n","        weights (dict, optional): A dictionary mapping model names to their weights.\n","                                  If None, each model is given equal weight.\n","\n","    Returns:\n","        list: A list of tuples containing the weighted average predictions and image IDs.\n","    \"\"\"\n","    predictions = []\n","\n","    # If no weights provided, assign equal weights to all models.\n","    if weights is None:\n","        weights = {name: 1.0 for name in models.keys()}\n","\n","    # Normalize weights so they sum to 1.\n","    total_weight = sum(weights.values())\n","    normalized_weights = {name: weight / total_weight for name, weight in weights.items()}\n","\n","    for batch in test_data:\n","        patches, _, image_ids = batch\n","\n","        # Initialize weighted predictions with zeros.\n","        batch_preds_weighted = np.zeros((patches.shape[0], 1))\n","\n","        # Accumulate predictions from each model multiplied by its normalized weight.\n","        for model_name, model in models.items():\n","            model_weight = normalized_weights.get(model_name, 0)\n","            preds = model.predict(patches, verbose=0)\n","            batch_preds_weighted += model_weight * preds\n","\n","        # Append weighted predictions along with corresponding image IDs.\n","        predictions.extend(zip(batch_preds_weighted.flatten(), image_ids.numpy()))\n","\n","    return predictions"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9ADY7OXdp4P9"},"outputs":[],"source":["def evaluate_individual_model(model, test_dataset, labels_df):\n","    \"\"\"\n","    Evaluates a single model's performance on a test dataset, grouping predictions by image ID.\n","\n","    Args:\n","        model (tf.keras.Model): The trained model to evaluate.\n","        test_dataset (tf.data.Dataset): Dataset containing test patches, labels, and image IDs.\n","        labels_df (pd.DataFrame): DataFrame with true labels and file IDs.\n","\n","    Returns:\n","        dict: Evaluation metrics including MAE, RMSE, RÂ², MAPE, and thresholds.\n","    \"\"\"\n","    predictions_with_ids = []\n","\n","    for batch in test_dataset:\n","        patches, _, image_ids = batch\n","        predictions = model.predict(patches, verbose=0).flatten()\n","        predictions_with_ids.extend(zip(predictions, image_ids.numpy()))\n","\n","    predicted_images, true_images = group_predictions_by_image_id(predictions_with_ids, labels_df)\n","\n","    return compute_evaluation_metrics(true_images, predicted_images)"]},{"cell_type":"markdown","metadata":{"id":"wk0bmfzuOXg4"},"source":["## Load Models and Test Set\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ubx3yAvWHqxN"},"outputs":[],"source":["trained_models = {}\n","model = 'InceptionV3'\n","\n","for i in range(1,6):\n","    model_name = f'{model}_fold{i}'\n","    trained_models[model_name] = tf.keras.models.load_model(f'/content/drive/MyDrive/HHD_AgeSplit/cross_validation/{model}/{model_name}_finetune.keras')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Yn8bA7Etg87V"},"outputs":[],"source":["# subset your labels to the test rows\n","test_df = labels_data[labels_data['Set']=='test'].reset_index(drop=True)\n","\n","test_dataset = patch_data_tf_dataset_with_ids(\n","    DATA_ROOT,         # root folder\n","    test_df,           # your subset DataFrame\n","    dataset_type='test',\n","    patch_size=(400,400),\n","    step_size=200,\n","    batch_size=BATCH_SIZE,\n","    augment=False\n",")"]},{"cell_type":"markdown","metadata":{"id":"mdRu2glgz-sx"},"source":["## Run Evaluations\n"]},{"cell_type":"markdown","metadata":{"id":"vk1WnZgM0gMJ"},"source":["### Ensemble Metrics"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"1zR4WR9bHyR6"},"outputs":[],"source":["# Generate predictions with image IDs\n","ensemble_predictions_with_ids = ensemble_predict(trained_models, test_dataset)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DZTqsDm_M82k"},"outputs":[],"source":["# Group prediction by image\n","predicted_images, true_images = group_predictions_by_image_id(ensemble_predictions_with_ids, labels_data)\n","\n","# Compute metrics\n","evaluation_metrics = compute_evaluation_metrics(true_images, predicted_images)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AU1xd_S6gm8G"},"outputs":[],"source":["import numpy as np\n","import itertools\n","from sklearn.metrics import mean_absolute_error\n","\n","def optimize_ensemble_weights(models, test_dataset, labels_df, search_space, start_index=0):\n","    \"\"\"\n","    Searches over a grid of weight values for each model to find the combination\n","    that produces the lowest MAE on the given test dataset, starting from a specified index.\n","\n","    Args:\n","        models (dict): Dictionary of trained models (keys are model names).\n","        test_dataset (tf.data.Dataset): Dataset yielding batches of (patches, labels, image_ids).\n","        labels_df (pd.DataFrame): DataFrame containing true labels with image IDs.\n","        search_space (dict): Dictionary mapping model names to a tuple (min, max, step) for weight search.\n","                             Example: {'ResNet50': (0.1, 0.5, 0.1), ...}\n","        start_index (int): The index of the weight combination from which to resume the grid search.\n","\n","    Returns:\n","        tuple: (best_weights, best_mae)\n","            - best_weights (dict): Weight combination with the lowest MAE.\n","            - best_mae (float): Corresponding MAE value.\n","    \"\"\"\n","    # Create lists of weight values for each model.\n","    weight_values = {\n","        model_name: np.arange(min_val, max_val + search_space[model_name][2], search_space[model_name][2])\n","        for model_name, (min_val, max_val, _) in search_space.items()\n","    }\n","\n","    # Generate all weight combinations.\n","    all_combinations = list(itertools.product(*[weight_values[m] for m in weight_values]))\n","\n","    best_weights = None\n","    best_mae = float('inf')\n","\n","    total_combinations = len(all_combinations)\n","    print(f\"Starting grid search with {total_combinations} combinations, resuming from index {start_index}.\")\n","\n","    # Resume from the specified start_index.\n","    for idx, combination in enumerate(all_combinations[start_index:], start=start_index):\n","        current_weights = dict(zip(weight_values.keys(), combination))\n","        # Skip combinations where the sum of weights is zero.\n","        if sum(current_weights.values()) == 0:\n","            continue\n","\n","        # Compute ensemble predictions using the current weight combination.\n","        ensemble_preds_with_ids = ensemble_predict_with_weights(models, test_dataset, current_weights)\n","        predicted_images, true_images = group_predictions_by_image_id(ensemble_preds_with_ids, labels_df)\n","        mae = mean_absolute_error(true_images, predicted_images)\n","\n","        print(f\"Combination {idx+1}/{total_combinations} - Weights: {current_weights} => MAE: {mae:.2f}\")\n","\n","        if mae < best_mae:\n","            best_mae = mae\n","            best_weights = current_weights.copy()\n","            print(f\"New best found: {best_weights} with MAE: {best_mae:.2f}\")\n","\n","    print(f\"Best weights found: {best_weights} with MAE: {best_mae:.2f}\")\n","    return best_weights, best_mae\n","\n","# Example usage:\n","search_space = {\n","    'ResNet50': (0.1, 0.5, 0.1),\n","    'DenseNet121': (0.1, 0.5, 0.1),\n","    'InceptionResNetV2': (0.1, 0.5, 0.1)\n","}\n","\n","# If your previous run stopped after processing 45 combinations, set start_index=45.\n","# best_weights, best_mae = optimize_ensemble_weights(trained_models, test_dataset, labels_data, search_space, start_index=85)\n","# best_weights, best_mae"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"44YLqs51HfH_"},"outputs":[],"source":["# weights = {\n","#     'ResNet50': 0.8,\n","#     # 'InceptionV3': 0.15,\n","#     # 'DenseNet121': 0.33,\n","#     # 'EfficientNetV2M': 0.1,\n","#     'InceptionResNetV2': 0.2\n","# }"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"Sp0UF1pOH1VD"},"outputs":[],"source":["# Generate predictions with image IDs\n","# ensemble_predictions_with_ids = ensemble_predict_with_weights(trained_models, test_dataset, weights)"]},{"cell_type":"markdown","metadata":{"id":"uAElK4Bk0j89"},"source":["### Individual Model Metrics"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BYf_d5zTqfMv"},"outputs":[],"source":["# Build a dictionary to store each model's predictions (after grouping by image ID)\n","model_predictions_dict = {}\n","true_ages = None  # Will be set once from the first modelâ€™s predictions\n","\n","for model_name, model in trained_models.items():\n","    print(f\"\\nEvaluating {model_name}...\")\n","    predictions_with_ids = []\n","\n","    # Iterate over the test dataset and gather predictions with image IDs\n","    for batch in test_dataset:\n","        patches, _, image_ids = batch\n","        preds = model.predict(patches, verbose=0).flatten()\n","        predictions_with_ids.extend(zip(preds, image_ids.numpy()))\n","\n","    # Group predictions by image ID (returns (predicted_ages, true_ages))\n","    model_preds, model_true = group_predictions_by_image_id(predictions_with_ids, labels_data)\n","\n","    # Store this model's predictions in the dictionary\n","    model_predictions_dict[model_name] = model_preds\n","\n","    # Set true_ages once (assuming all models cover the same test set)\n","    if true_ages is None:\n","        true_ages = model_true\n","\n","    # Optionally, compute and display individual evaluation metrics\n","    _ = compute_evaluation_metrics(model_true, model_preds)\n","    print(\"\\n\\n\")"]},{"cell_type":"markdown","metadata":{"id":"tlnNw3PiJAxE"},"source":["### Kappa"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_XGKyE2mQTVg"},"outputs":[],"source":["def classify_age(age):\n","    \"\"\"\n","    Classifies a continuous age value into one of four age groups.\n","\n","    Args:\n","        age (float): The age value.\n","\n","    Returns:\n","        int: Age group number (1 to 4).\n","            1: Age â‰¤ 15\n","            2: 16 â‰¤ Age â‰¤ 25\n","            3: 26 â‰¤ Age â‰¤ 50\n","            4: Age > 50\n","    \"\"\"\n","    if age <= 15:\n","        return 1\n","    elif age <= 25:\n","        return 2\n","    elif age <= 50:\n","        return 3\n","    else:\n","        return 4"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kOildCkNJGc2"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import itertools\n","import warnings\n","from sklearn.metrics import confusion_matrix, cohen_kappa_score\n","\n","def analyze_model_agreement(true_ages, model_predictions_dict, plot=True):\n","    \"\"\"\n","    Analyzes agreement between models' age predictions.\n","\n","    This function:\n","      1. Converts continuous predictions (and true ages) into categorical age groups\n","         using your standard `classify_age` function.\n","      2. Computes a confusion matrix (predicted vs. true categories) for each model.\n","      3. Computes pairwise Cohen's kappa scores between models to assess how similarly they predict.\n","      4. Optionally computes Fleiss' kappa for overall multi-model agreement.\n","      5. Optionally plots:\n","          - The confusion matrix for each model (with age group labels).\n","          - A heatmap of pairwise Cohen's kappa scores (with model names).\n","\n","    Args:\n","        true_ages (np.ndarray): Array of true continuous ages.\n","        model_predictions_dict (dict): Dictionary where keys are model names and values are arrays\n","                                       of predicted continuous ages.\n","        plot (bool): Whether to generate plots.\n","\n","    Returns:\n","        dict: Dictionary containing:\n","            - 'confusion_matrices': dict mapping each model name to its confusion matrix.\n","            - 'pairwise_kappa': 2D numpy array of pairwise Cohen's kappa scores.\n","            - 'model_names': List of model names (order corresponds to pairwise_kappa rows/columns).\n","            - 'fleiss_kappa': Fleiss' kappa score across all models (if computed, else None).\n","    \"\"\"\n","    # Define the complete set of categorical labels\n","    labels_categories = [1, 2, 3, 4]\n","\n","    # Convert true ages into categorical groups using classify_age\n","    true_categories = np.array([classify_age(age) for age in true_ages])\n","\n","    # Compute confusion matrices for each model and store each model's categorical predictions.\n","    confusion_matrices = {}\n","    model_categories = {}\n","    for model_name, predictions in model_predictions_dict.items():\n","        # Convert continuous predictions into age groups using the same binning strategy.\n","        preds_categories = np.array([classify_age(age) for age in predictions])\n","        model_categories[model_name] = preds_categories\n","\n","        # Warn if a model's predictions have only one unique category.\n","        unique_preds = np.unique(preds_categories)\n","        if len(unique_preds) == 1:\n","            print(f\"Warning: Model {model_name} produced only one category: {unique_preds}\")\n","\n","        # Suppress warning from confusion_matrix about a single label by using a warnings context.\n","        with warnings.catch_warnings():\n","            warnings.filterwarnings(\"ignore\", message=\"A single label was found in\")\n","            cm = confusion_matrix(true_categories, preds_categories, labels=labels_categories)\n","        confusion_matrices[model_name] = cm\n","\n","        if plot:\n","            # Plot the confusion matrix for the model.\n","            age_labels = ['<=15', '16-25', '26-50', '>50']\n","            plt.figure(figsize=(6, 5))\n","            plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n","            plt.title(f'Confusion Matrix - {model_name}')\n","            plt.colorbar()\n","            tick_marks = np.arange(len(age_labels))\n","            plt.xticks(tick_marks, age_labels)\n","            plt.yticks(tick_marks, age_labels)\n","            thresh = cm.max() / 2.0 if cm.max() > 0 else 1\n","            for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n","                plt.text(j, i, format(cm[i, j], 'd'),\n","                         horizontalalignment=\"center\",\n","                         color=\"white\" if cm[i, j] > thresh else \"black\")\n","            plt.ylabel('True Age Groups')\n","            plt.xlabel('Predicted Age Groups')\n","            plt.tight_layout()\n","            plt.show()\n","\n","    # Compute pairwise Cohen's kappa scores between models (using their categorical predictions).\n","    model_names = list(model_predictions_dict.keys())\n","    n_models = len(model_names)\n","    pairwise_kappa = np.zeros((n_models, n_models))\n","    for i in range(n_models):\n","        for j in range(n_models):\n","            if i == j:\n","                pairwise_kappa[i, j] = 1.0\n","            else:\n","                preds_i = model_categories[model_names[i]]\n","                preds_j = model_categories[model_names[j]]\n","                # If either prediction set has less than 2 unique values, assign 0.\n","                if len(np.unique(preds_i)) < 2 or len(np.unique(preds_j)) < 2:\n","                    kappa = 0.0\n","                else:\n","                    kappa = cohen_kappa_score(preds_i, preds_j, labels=labels_categories)\n","                    # If kappa is NaN, substitute with 0.\n","                    if np.isnan(kappa):\n","                        kappa = 0.0\n","                pairwise_kappa[i, j] = kappa\n","\n","    if plot:\n","        # Plot heatmap of pairwise Cohen's kappa scores.\n","        plt.figure(figsize=(8, 6))\n","        plt.imshow(pairwise_kappa, interpolation='nearest', cmap=plt.cm.Blues)\n","        plt.title(\"Pairwise Cohen's Kappa Between Models\")\n","        plt.colorbar()\n","        tick_marks = np.arange(n_models)\n","        plt.xticks(tick_marks, model_names, rotation=45)\n","        plt.yticks(tick_marks, model_names)\n","        for i in range(n_models):\n","            for j in range(n_models):\n","                plt.text(j, i, f\"{pairwise_kappa[i, j]:.2f}\",\n","                         horizontalalignment=\"center\",\n","                         color=\"white\" if pairwise_kappa[i, j] > 0.5 else \"black\")\n","        plt.tight_layout()\n","        plt.show()\n","\n","    # Compute Fleiss' Kappa for multi-model agreement (optional)\n","    # Prepare a ratings matrix: each row corresponds to a test instance,\n","    # and each column counts how many models predicted each age group.\n","    n_samples = len(true_categories)\n","    n_categories = len(labels_categories)\n","    ratings = np.zeros((n_samples, n_categories), dtype=int)\n","    for i in range(n_samples):\n","        for model_name in model_names:\n","            rating = model_categories[model_name][i]\n","            # Adjust index: category 1 -> index 0, etc.\n","            ratings[i, rating - 1] += 1\n","    try:\n","        from statsmodels.stats.inter_rater import fleiss_kappa\n","        fleiss = fleiss_kappa(ratings, method='fleiss')\n","    except ImportError:\n","        print(\"statsmodels is required for Fleiss' kappa. Skipping this metric.\")\n","        fleiss = None\n","\n","    results = {\n","        \"confusion_matrices\": confusion_matrices,\n","        \"pairwise_kappa\": pairwise_kappa,\n","        \"model_names\": model_names,\n","        \"fleiss_kappa\": fleiss\n","    }\n","\n","    return results\n","\n","\n","# Now that all models have been evaluated, analyze the inter-model agreement\n","results = analyze_model_agreement(true_ages, model_predictions_dict, plot=True)\n","\n","# Example output:\n","print(\"Pairwise Cohen's Kappa Matrix:\")\n","print(results['pairwise_kappa'])\n","if results['fleiss_kappa'] is not None:\n","    print(\"Fleiss' Kappa (multi-model agreement):\", results['fleiss_kappa'])"]},{"cell_type":"markdown","metadata":{"id":"FHc49Xwhz5X3"},"source":["## Save image predictions to csv\n"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"13Q46qXN0Ap2"},"outputs":[],"source":["import os, csv\n","from collections import defaultdict\n","import tensorflow as tf\n","\n","# 1ï¸âƒ£ Configure these:\n","MODEL_NAMES = ['ResNet50','DenseNet121','InceptionV3','InceptionResNetV2','EfficientNetV2M']\n","\n","\n","FOLDS       = range(1, 6)\n","CKPT_ROOT   = '/content/drive/MyDrive/HHD_AgeSplit/cross_validation'\n","OUT_DIR     = '/content/drive/MyDrive/HHD_AgeSplit/cross_validation/image_level_preds'\n","os.makedirs(OUT_DIR, exist_ok=True)\n","\n","# 2ï¸âƒ£ Your test dataset generator (patch-level):\n","#    Must yield (patches, labels, image_ids) where image_ids are bytes strings.\n","\n","# subset your labels to the test rows\n","test_df = labels_data[labels_data['Set']=='test'].reset_index(drop=True)\n","\n","test_dataset = patch_data_tf_dataset_with_ids(\n","    DATA_ROOT,         # root folder\n","    test_df,           # your subset DataFrame\n","    dataset_type='test',\n","    patch_size=(400,400),\n","    step_size=200,\n","    batch_size=BATCH_SIZE,\n","    augment=False\n",")\n","\n","for model_name in MODEL_NAMES:\n","    for fold in FOLDS:\n","        print(f\"\\nâ†’ Predicting {model_name} fold {fold}â€¦\")\n","\n","        # â€” load the finetuned fold checkpoint\n","        ckpt_path = os.path.join(\n","            CKPT_ROOT,\n","            model_name,\n","            f\"{model_name}_fold{fold}_finetune.keras\"\n","        )\n","        model = tf.keras.models.load_model(ckpt_path)\n","\n","        # â€” accumulate patch preds in a dict: { image_id â†’ [pred1, pred2, â€¦] }\n","        preds_per_image = defaultdict(list)\n","        for patches, _, image_ids in test_dataset:\n","            # shape (batch,1) â†’ flatten to (batch,)\n","            preds = model.predict(patches, verbose=0).ravel()\n","            for img_id_bytes, p in zip(image_ids.numpy(), preds):\n","                img_id = img_id_bytes.decode('utf-8')\n","                preds_per_image[img_id].append(float(p))\n","\n","        # â€” write image-level CSV for this fold (mean of its patches)\n","        csv_path = os.path.join(\n","            OUT_DIR,\n","            f\"{model_name}_fold{fold}_image_preds.csv\"\n","        )\n","        with open(csv_path, 'w', newline='') as f:\n","            writer = csv.writer(f)\n","            writer.writerow(['Model','Fold','ImageID','Image_Prediction'])\n","            for img_id, plist in preds_per_image.items():\n","                mean_pred = sum(plist) / len(plist)\n","                writer.writerow([model_name, fold, img_id, mean_pred])\n","\n","        print(f\"  âœ”ï¸ Saved {csv_path}\")\n","\n","        # â€” free GPU memory before next model/fold\n","        tf.keras.backend.clear_session()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KThpMU8G4t-i"},"outputs":[],"source":["import glob\n","import pandas as pd\n","\n","# 1ï¸âƒ£ Grab all the image-level CSVs\n","pattern = os.path.join(OUT_DIR, '*_image_preds.csv')\n","files = glob.glob(pattern)\n","\n","# 2ï¸âƒ£ Read & concat\n","df = pd.concat((pd.read_csv(f) for f in files), ignore_index=True)\n","\n","# 3ï¸âƒ£ Ensemble by mean over all (Model,Fold) predictions per image\n","ensemble_df = (\n","    df\n","    .groupby('ImageID', as_index=False)['Image_Prediction']\n","    .mean()\n","    .rename(columns={'Image_Prediction':'Ensemble_Prediction'})\n",")\n","\n","# 4ï¸âƒ£ Save\n","ensemble_csv = os.path.join(OUT_DIR, 'ensemble_image_predictions.csv')\n","ensemble_df.to_csv(ensemble_csv, index=False)\n","\n","print(f\"âœ… Ensemble saved to {ensemble_csv}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"chpmBgpd6dSg"},"outputs":[],"source":["import os, numpy as np, pandas as pd\n","from collections import defaultdict\n","\n","# --- Paths & constants --------------------------------------------------\n","OUT_DIR      = '/content/drive/MyDrive/HHD_AgeSplit/cross_validation/image_level_preds'\n","ENSEMBLE_CSV = os.path.join(OUT_DIR, 'ensemble_image_predictions.csv')\n","MODEL_NAMES = ['ResNet50','DenseNet121','InceptionV3','InceptionResNetV2','EfficientNetV2M']\n","\n","FOLDS        = range(1, 6)\n","\n","# --- True labels (image-level) ------------------------------------------\n","test_df  = labels_data[labels_data['Set'] == 'test'].reset_index(drop=True)\n","true_df  = test_df[['File', 'Age']].rename(columns={'File': 'ImageID',\n","                                                    'Age' : 'TrueAge'})\n","\n","# =========================================================================\n","# 1) ð™€ð™‰ð™Žð™€ð™ˆð˜½ð™‡ð™€ â€“ all models & folds combined\n","# =========================================================================\n","ens_df      = pd.read_csv(ENSEMBLE_CSV)\n","ens_merged  = ens_df.merge(true_df, on='ImageID')\n","print(\"\\nðŸ“Š  Ensemble metrics (all models + folds)\")\n","_ = compute_evaluation_metrics(ens_merged['TrueAge'].values,\n","                               ens_me   rged['Ensemble_Prediction'].values)\n","\n","# =========================================================================\n","# 2) ð™ˆð™Šð˜¿ð™€ð™‡-ð™‡ð™€ð™‘ð™€ð™‡ ð™ˆð™€ð™ð™ð™„ð˜¾ð™Ž â€“ mean Â± std over its folds\n","# =========================================================================\n","print(\"\\nâ”€â”€â”€â”€â”€â”€â”€â”€ Individual models (mean Â± std over folds) â”€â”€â”€â”€â”€â”€â”€â”€\")\n","for model_name in MODEL_NAMES:\n","    fold_mae = []\n","    preds_per_image = defaultdict(list)   # collect fold preds â†’ model-level avg later\n","\n","    for fold in FOLDS:\n","        csv_path = os.path.join(OUT_DIR,\n","                                f\"{model_name}_fold{fold}_image_preds.csv\")\n","        df_fold  = (pd.read_csv(csv_path)\n","                      .rename(columns={'Image_Prediction': 'Pred'}))\n","        merged   = df_fold.merge(true_df, on='ImageID')\n","\n","        # ---- per-fold MAE (quiet) --------------------------------------\n","        mae = np.mean(np.abs(merged['TrueAge'].values - merged['Pred'].values))\n","        fold_mae.append(mae)\n","\n","        # gather predictions for the model-level average\n","        for img, p in zip(merged['ImageID'], merged['Pred']):\n","            preds_per_image[img].append(p)\n","\n","    # ---- model-level predictions: mean over its 5 folds ---------------\n","    model_avg_preds = {img: np.mean(plist) for img, plist in preds_per_image.items()}\n","    model_df        = pd.DataFrame(list(model_avg_preds.items()),\n","                                   columns=['ImageID', 'Model_Pred'])\n","    merged_model    = model_df.merge(true_df, on='ImageID')\n","\n","    print(f\"\\nðŸ”¹ {model_name}\")\n","    _ = compute_evaluation_metrics(merged_model['TrueAge'].values,\n","                                   merged_model['Model_Pred'].values)\n","\n","    # compact MAE summary\n","    print(f\"   MAE (fold mean Â± std): {np.mean(fold_mae):.2f} Â± {np.std(fold_mae):.2f}\")\n"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["abkqHkNVZiav","ILgTHuUi0IUX","wk0bmfzuOXg4","mdRu2glgz-sx","vk1WnZgM0gMJ","uAElK4Bk0j89","tlnNw3PiJAxE"],"gpuType":"A100","machine_shape":"hm","provenance":[{"file_id":"1rcOLEuyFuujZ11TubFFCaTd9lpvlN7Ow","timestamp":1747468811162},{"file_id":"1-lbZgDHP_f6w-zA2iJ5XLRxe86pSRDD0","timestamp":1740302230106},{"file_id":"1E7XVe7s7krkBgHmHF1xHVQSW3-HA1wnS","timestamp":1737130270583},{"file_id":"14M5I5jvx32ttEF3HFGCvpBJ7mGBF2lWL","timestamp":1736670846297}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}